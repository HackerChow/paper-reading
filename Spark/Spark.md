# RDDs导读
## Abstract
RDDs对分布式内存进行抽象，使得可以进行内存中的计算。这个特点使得它很适合做迭代式的计算和交互式的数据挖掘。

fault-tolerant，RDDs对共享内存提供了严格的形式。基于粗粒度的转换而不是细粒度的更新。
### 关键词：
1. in-memory computation
2. fault-tolerant
3. coarse-grained transformations

## Introduction
现行的一些分布式计算框架比如，mapreduce，缺乏对分布式内存的抽象。这使得它们很难复用中间结果，比如mapreduce把中间结果存在磁盘上，每次读取都很慢。所以使得他们在做，迭代式的任务，比如机器学习，图算法的时候很难受，像训练网络的时候肯定希望参数一直驻留在内存里。同时，由于磁盘IO什么的很慢，所以做一些交互式的任务的时候延迟会很大。  

当然现在有很多框架，比如Pregel为了进行交互式的图计算，把中间结果存在内存中。还有HaLoop是一个迭代式的mapreduce框架。他们做的确实不错，但是他们都是为了进行某个特定的应用而被构建出来的，缺乏通用性。  

所以本文构建了resilient distributed datasets来解决上述的问题。
1. RDDs是容错的，并行化的数据结构
2. 用户可以明确的将中间结果存在内存中
3. 控制它们的划分从而优化数据放置
4. 使用一系列的“算子”操作它们  

设计RDDs最大的难点在于如何高效地做到容错，现行的集群内存共享策略比如distributed shared memory都是基于细粒度的更新（我觉得可能就是随机写吧，比如我要改一张表里的一个cell，本文没展开，但我觉得蛮有趣的，有空再看），所以它们都是用数据备份和写日志的方式来容错的，但是这样的话在数据密集的任务中会十分耗时。（写日志容错一般都要写metadata和data）

所以为了解决上述的问题，RDDs放弃了细粒度更新，转而变为粗粒度的数据转换。这样的话就不用在日志里记录具体的数据了，而只用记录操作（原文里称为“血缘”）。这样的话，如果我丢了一个RDD，那我还是知道这个RDD是怎么来的，那重新计算得到这个RDD就很容易。比如有一个动物数据集，然后我对这个数据集进行了一个filter的操作，我想得到所有狗的图片作为一个RDD，这样我就把这个操作记录下来。然后电脑挂了，我丢了这个RDD，那我只要再过滤一遍就可以恢复这个RDD了。

本文作者认为，虽然这个粗粒度的数据转换看起来很局限，但实际上它的表达能力是很强的，可以用来实现很多框架比如mapreduce。同时他认为RDDs的强大的适应能力(可以实现很多不同功能的应用)是它最有价值的地方。

## Resilient Distributed Datasets
### RDDs的特征有：
1. 只读
2. 分区
3. RDD只能用特定的operation来创造（比如map，filter，join），数据来源只能是稳定存储介质中的数据（比如磁盘）或者其他RDDs。
4. RDDs不用任何时候被具象化实现（我理解下来就是有真实存在的数据），但是RDDs有足够的信息（log中记录的operation，也就是它的“血缘”）来知道这个RDD是怎么被构造出来的。所以说一个RDD要被程序使用的话，它必须能够被重建。（“血缘”保存完整）。
5. 用户可以控制RDDs的persistence和分区，也就是用户可以指明我要复用哪个RDD，还有这个RDD要怎么存（比如存在内存里)  用户也可以指明, 这个RDD要怎么分区到不同的机器上,通过指定每条记录中的keyword(我对这个的理解就是比如动物数据集,我要不同动物的图片存在不同机器上,所以我的keyword就是species)

### Spark 编程接口
在Spark框架下,每个数据集都是一个对象,然后数据转换是通过调用这些对象的方法来完成的.  

首先用户通过对存在稳定介质中的数据进行转换(比如map或者filter)来定义RDDs.之后用户就可以对这些RDDs使用各种动作(action)了,比如count(返回一个RDD中的数据个数),collect(返回一个RDD中的数据),save(保存数据集)。

文章在这里提到了Spark的一个关键特性"延迟计算",下面解释一下。上面已经说到了对RDD有两类操作，一类是数据转换operation（比如map，filter），第二类是动作action（比如count，collect）。延迟计算的意思是，比如现在有一个动物数据集animals，我写了两行代码

dogs=animals.filter（species=dog）  
maledogs=dogs.filter（gender=male）

写完两行代码之后，我想得到所有公狗的信息，但其实此时由于我只是调用了两个operation，spark还没有真正计算得到这个数据集。它只是记录了要得到这个数据集需要进行哪些操作，在这里就是简单的两次过滤操作，为了得到真正的数据，我需要再加一行代码。  

maledogs.collect（）

这时候我调用了一个action，所以spark会真正的计算出这个数据集。这个懒惰计算的好处就是它可以对连续的几个operation进行流水操作，提高效率。

除此之外，用户还可以调用persist方法（persist属于一个transform operation，也会被懒惰执行）来指明他们想复用哪一个RDD，spark的默认存储是内存，但是用户可以指定（存在磁盘，或者存多个副本在不同机器上）。当然内存不够的时候，spark会进行换出操作，用户可以指定RDD的换出优先级。

### RDD模型的优势
1. RDD只支持粗粒度的转换，所以它只能用作bulk write应用，但它能十分高效地进行容错（通过使用“血缘”）  
2. 此外，RDDs不可改变的特性使得spark可以通过对慢任务进行backup copies来加快执行。但是像DSM这种，就很难做到，因为同一个任务的不同备份会访问同一个全局的位置，那么他们之间就会影响彼此，比如交替update（我猜DSM就是把不同机器的内存拼在一起变成一大块内存，然后每一个内存块都有一个全局的地址）。
3. 最后RDDs比起DSM还有两大优势，首先，对于RDDs的bulk operation，spark runtime程序可以基于数据局部性来调度任务。其次，RDDs在没有足够内存的时候可以优雅地进行降级，只要操作是scan-based operation，就是简单的把存不下的数据放到磁盘上。
4. spark适合做批处理任务，也就是对一堆数据采用同一个操作的任务，不适合做那些对一个共享状态（我觉得就是指共享数据吧）进行精细化异步更新的任务。