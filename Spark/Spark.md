# RDDs导读
## Abstract
RDDs对分布式内存进行抽象，使得可以进行内存中的计算。这个特点使得它很适合做迭代式的计算和交互式的数据挖掘。

fault-tolerant，RDDs对共享内存提供了严格的形式。基于粗粒度的转换而不是细粒度的更新。
### 关键词：
1. in-memory computation
2. fault-tolerant
3. coarse-grained transformations

## Introduction
现行的一些分布式计算框架比如，mapreduce，缺乏对分布式内存的抽象。这使得它们很难复用中间结果，比如mapreduce把中间结果存在磁盘上，每次读取都很慢。所以使得他们在做，迭代式的任务，比如机器学习，图算法的时候很难受，像训练网络的时候肯定希望参数一直驻留在内存里。同时，由于磁盘IO什么的很慢，所以做一些交互式的任务的时候延迟会很大。  

当然现在有很多框架，比如Pregel为了进行交互式的图计算，把中间结果存在内存中。还有HaLoop是一个迭代式的mapreduce框架。他们做的确实不错，但是他们都是为了进行某个特定的应用而被构建出来的，缺乏通用性。  

所以本文构建了resilient distributed datasets来解决上述的问题。
1. RDDs是容错的，并行化的数据结构
2. 用户可以明确的将中间结果存在内存中
3. 控制它们的划分从而优化数据放置
4. 使用一系列的“算子”操作它们  

设计RDDs最大的难点在于如何高效地做到容错，现行的集群内存共享策略比如distributed shared memory都是基于细粒度的更新（我觉得可能就是随机写吧，比如我要改一张表里的一个cell，本文没展开，但我觉得蛮有趣的，有空再看），所以它们都是用数据备份和写日志的方式来容错的，但是这样的话在数据密集的任务中会十分耗时。（写日志容错一般都要写metadata，和data）

所以为了解决上述的问题，RDDs放弃了细粒度更新，转而变为粗粒度的数据转换。这样的话就不用在日志里记录具体的数据了，而只用记录操作（原文里称为“血缘”）。这样的话，如果我丢了一个RDD，那我还是知道这个RDD是怎么来的，那重新计算得到这个RDD就很容易。比如有一个动物数据集，然后我对这个数据集进行了一个，filter的操作，我想得到所有狗的图片作为一个RDD，这样我就把这个操作记录下来。然后电脑挂了，我丢了这个RDD，那我只要再过滤一遍就可以恢复这个RDD了。

本文作者认为，虽然这个粗粒度的数据转换看起来很局限，但实际上它的表达能力是很强的，可以用来实现很多框架比如mapreduce。同时他认为RDDs的强大的适应能力是它最有价值的地方。

## Resilient Distributed Datasets
RDDs的特征有：
1. 只读
2. 分区
3. RDD只能用特定的operation来创造（比如map，filter，join），数据来源只能是稳定存储介质中的数据（比如磁盘）或者其他RDDs。
4. RDDs不用任何时候被具象化实现（我理解下来就是有真实存在的数据），但是RDDs有足够的信息（log中记录的operation，也就是它的“血缘”）来知道这个RDD是怎么被构造出来的。所以说一个RDD要被程序使用的话，它必须能够被重建。（“血缘”保存完整）。
5. 用户可以控制RDDs的persistence和分区，也就是用户可以指明我要复用哪个RDD，还有这个RDD要怎么存（比如存在内存里)  用户也可以指明, 这个RDD要怎么分区到不同的机器上,通过指定每条记录中的keyword(我对这个的理解就是比如动物数据集,我要不同动物的图片存在不同机器上,所以我的keyword就是species)

